{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "registry_pth = os.path.join(\"..\", \"evals\", \"registry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_prompt(word):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"Please state the number of syllables in the input word. Reply only with a number and nothing else.\"}, \n",
    "        {\"role\": \"user\", \"content\": word}\n",
    "    ]\n",
    "\n",
    "# Read the file and create DataFrames\n",
    "for i in range(5, 7):\n",
    "    df = pd.read_csv('syllables_dataset/' + str(i) + '_syllables_sorted_by_prevalence.txt', header=None, names=[\"word\"], lineterminator='\\n')\n",
    "    df[\"input\"], df[\"ideal\"] = df[\"word\"].apply(create_chat_prompt), str(i)\n",
    "    df = df[[\"input\", \"ideal\"]]\n",
    "    df.to_json(os.path.join(registry_pth, \"data/syllables_long_words/\" + str(i) + \"_syllables.jsonl\"), orient=\"records\", lines=True)\n",
    "    df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_yaml = \"\"\"\n",
    "syllables_long_words:\n",
    "  id: syllables.dev.v1\n",
    "  metrics: [accuracy]\n",
    "syllables.dev.v1:\n",
    "  class: evals.elsuite.basic.match:Match\n",
    "  args:\n",
    "    samples_jsonl: syllables_long_words/long_word_samples.jsonl  \n",
    "\"\"\".strip()\n",
    "with open(os.path.join(registry_pth, \"evals\", \"syllables_long_words.yaml\"), \"wb\") as f:\n",
    "    # Encode the text and replace CRLF with LF, because this may be run on Windows\n",
    "    encoded_text = eval_yaml.encode('utf-8').replace(b'\\r\\n', b'\\n')\n",
    "    \n",
    "    # Write the encoded text to the file\n",
    "    f.write(encoded_text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current evals module is used to run the oaieval task. Within your virtual environment, create a file in site-packages with extension .pth which contains the full path to the evals python code. For example, module.pth with line C:\\dev\\play\\evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-23 17:04:58,324] [registry.py:249] Loading registry from C:\\dev\\play\\evals\\evals\\registry\\evals\n",
      "[2023-05-23 17:04:59,042] [registry.py:249] Loading registry from C:\\Users\\ekane\\.evals\\evals\n",
      "[2023-05-23 17:04:59,047] [oaieval.py:110] \u001b[1;35mRun started: 2305232104592TSYCYBQ\u001b[0m\n",
      "[2023-05-23 17:04:59,052] [data.py:75] Fetching syllables_long_words/long_word_samples.jsonl\n",
      "[2023-05-23 17:04:59,063] [eval.py:34] Evaluating 100 samples\n",
      "[2023-05-23 17:04:59,076] [eval.py:153] Running in threaded mode with 10 threads!\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  1%|          | 1/100 [00:00<01:32,  1.07it/s]\n",
      "  5%|▌         | 5/100 [00:01<00:15,  6.12it/s]\n",
      "  8%|▊         | 8/100 [00:01<00:09,  9.55it/s]\n",
      " 11%|█         | 11/100 [00:01<00:10,  8.59it/s]\n",
      " 13%|█▎        | 13/100 [00:01<00:10,  8.16it/s]\n",
      " 15%|█▌        | 15/100 [00:02<00:09,  8.81it/s]\n",
      " 17%|█▋        | 17/100 [00:02<00:09,  8.38it/s]\n",
      " 20%|██        | 20/100 [00:02<00:08,  9.52it/s]\n",
      " 22%|██▏       | 22/100 [00:02<00:08,  9.65it/s]\n",
      " 24%|██▍       | 24/100 [00:02<00:07, 10.02it/s]\n",
      " 26%|██▌       | 26/100 [00:03<00:06, 11.59it/s]\n",
      " 28%|██▊       | 28/100 [00:03<00:05, 12.62it/s]\n",
      " 30%|███       | 30/100 [00:03<00:05, 12.70it/s]\n",
      " 32%|███▏      | 32/100 [00:03<00:07,  9.29it/s]\n",
      " 34%|███▍      | 34/100 [00:03<00:06, 10.10it/s]\n",
      " 36%|███▌      | 36/100 [00:03<00:05, 10.87it/s]\n",
      " 38%|███▊      | 38/100 [00:04<00:06, 10.28it/s]\n",
      " 40%|████      | 40/100 [00:04<00:05, 11.99it/s]\n",
      " 42%|████▏     | 42/100 [00:04<00:05, 11.22it/s]\n",
      " 45%|████▌     | 45/100 [00:04<00:04, 11.62it/s]\n",
      " 47%|████▋     | 47/100 [00:05<00:06,  8.72it/s]\n",
      " 49%|████▉     | 49/100 [00:05<00:05,  9.29it/s]\n",
      " 51%|█████     | 51/100 [00:05<00:06,  7.91it/s]\n",
      " 52%|█████▏    | 52/100 [00:05<00:06,  7.26it/s]\n",
      " 53%|█████▎    | 53/100 [00:05<00:06,  7.14it/s]\n",
      " 56%|█████▌    | 56/100 [00:06<00:05,  8.45it/s]\n",
      " 59%|█████▉    | 59/100 [00:06<00:03, 10.95it/s]\n",
      " 61%|██████    | 61/100 [00:06<00:03, 10.91it/s]\n",
      " 64%|██████▍   | 64/100 [00:06<00:03,  9.33it/s]\n",
      " 67%|██████▋   | 67/100 [00:07<00:02, 12.18it/s]\n",
      " 69%|██████▉   | 69/100 [00:07<00:02, 11.19it/s]\n",
      " 72%|███████▏  | 72/100 [00:07<00:02,  9.37it/s]\n",
      " 74%|███████▍  | 74/100 [00:07<00:02, 10.49it/s]\n",
      " 76%|███████▌  | 76/100 [00:08<00:02,  9.11it/s]\n",
      " 79%|███████▉  | 79/100 [00:08<00:02,  9.46it/s]\n",
      " 81%|████████  | 81/100 [00:08<00:02,  9.41it/s]\n",
      " 83%|████████▎ | 83/100 [00:08<00:01,  8.74it/s]\n",
      " 86%|████████▌ | 86/100 [00:09<00:01,  9.02it/s]\n",
      " 88%|████████▊ | 88/100 [00:09<00:01,  8.39it/s]\n",
      " 91%|█████████ | 91/100 [00:09<00:00, 10.37it/s][2023-05-23 17:05:09,119] [record.py:309] Logged 185 rows of events to /tmp/evallogs/2305232104592TSYCYBQ_gpt-3.5-turbo_syllables_long_words.jsonl: insert_time=16.029ms\n",
      "\n",
      " 93%|█████████▎| 93/100 [00:10<00:00,  8.86it/s]\n",
      " 96%|█████████▌| 96/100 [00:10<00:00, 11.04it/s]\n",
      " 98%|█████████▊| 98/100 [00:11<00:00,  5.10it/s][2023-05-23 17:05:33,322] [_common.py:105] Backing off openai_chat_completion_create_retrying(...) for 0.7s (openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f371cfd281acefadfc41b633c40cbeaf in your message.))\n",
      "\n",
      " 99%|█████████▉| 99/100 [00:35<00:03,  3.86s/it][2023-05-23 17:05:36,420] [_common.py:105] Backing off openai_chat_completion_create_retrying(...) for 1.3s (openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 35803210b7626843ea285de7b8e625c3 in your message.))\n",
      "\n",
      "100%|██████████| 100/100 [00:39<00:00,  3.86s/it]\n",
      "100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "[2023-05-23 17:05:38,474] [record.py:320] Final report: {'accuracy': 0.7}. Logged to /tmp/evallogs/2305232104592TSYCYBQ_gpt-3.5-turbo_syllables_long_words.jsonl\n",
      "[2023-05-23 17:05:38,474] [oaieval.py:147] Final report:\n",
      "[2023-05-23 17:05:38,475] [oaieval.py:149] accuracy: 0.7\n",
      "[2023-05-23 17:05:38,476] [record.py:309] Logged 15 rows of events to /tmp/evallogs/2305232104592TSYCYBQ_gpt-3.5-turbo_syllables_long_words.jsonl: insert_time=1.000ms\n"
     ]
    }
   ],
   "source": [
    "!py ../evals/cli/oaieval.py gpt-3.5-turbo syllables_long_words --max_samples 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
